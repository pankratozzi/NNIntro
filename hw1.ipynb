{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9e355ba4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import trange\n",
    "\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import TensorDataset, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "316d4efa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_one_hot(Y):\n",
    "    n_col = np.amax(Y) + 1\n",
    "    binarized = np.zeros((len(Y), n_col))\n",
    "    for i in range(len(Y)):\n",
    "        binarized[i, Y[i]] = 1.\n",
    "    return binarized\n",
    "\n",
    "def from_one_hot(Y):\n",
    "    arr = np.zeros((len(Y), 1))\n",
    "    for i in range(len(Y)):\n",
    "        l = layer2[i]\n",
    "        for j in range(len(l)):\n",
    "            if(l[j] == 1):\n",
    "                arr[i] = j+1\n",
    "    return arr\n",
    "\n",
    "def sigmoid(x):\n",
    "    return 1/(1+np.exp(-x))\n",
    "\n",
    "def relu(x):\n",
    "    return x * (x > 0)\n",
    "\n",
    "def relu_deriv(x):\n",
    "    return x > 0\n",
    "\n",
    "def sigmoid_deriv(x):\n",
    "    return sigmoid(x)*(1 - sigmoid(x))\n",
    "\n",
    "def normalize(X, axis=-1, order=2):\n",
    "    l2 = np.atleast_1d(np.linalg.norm(X, order, axis))\n",
    "    l2[l2 == 0] = 1\n",
    "    return X / np.expand_dims(l2, axis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "bdd58738",
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = load_iris(return_X_y=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "459ee379",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = normalize(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "7e406317",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = to_one_hot(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "1868ba6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "710aca46",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "w0 = 2*np.random.random((4, 20)) - 1 # для входного слоя - 4 входа, 20 выхода\n",
    "w1 = 2*np.random.random((20, 10)) - 1 # для внутреннего слоя - 20 входов, 10 выхода\n",
    "w2 = 2*np.random.random((10, 3)) - 1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "d972fa85",
   "metadata": {},
   "outputs": [],
   "source": [
    "# вариант с нормальным распределением: что-то похожее происходит в PyTorch в Linear\n",
    "stdv = 1. / np.sqrt(4)\n",
    "w0 = np.random.uniform(low=-stdv, high=stdv, size=(4, 20))\n",
    "stdv = 1. / np.sqrt(20)\n",
    "w1 = np.random.uniform(low=-stdv, high=stdv, size=(20, 10))\n",
    "stdv = 1. / np.sqrt(10)\n",
    "w2 = np.random.uniform(low=-stdv, high=stdv, size=(10, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "699fe9ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "e8e8707f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████| 900000/900000 [00:49<00:00, 18300.54it/s]\n"
     ]
    }
   ],
   "source": [
    "errors = []\n",
    "\n",
    "for i in trange(900000):\n",
    "    # прямое распространение(feed forward)\n",
    "    layer0 = X_train\n",
    "    layer1 = relu(np.dot(layer0, w0))\n",
    "    layer2 = relu(np.dot(layer1, w1))\n",
    "    layer3 = sigmoid(np.dot(layer2, w2))\n",
    "    \n",
    "    layer3_error = y_train - layer3\n",
    "    layer3_delta = layer3_error * sigmoid_deriv(layer3)\n",
    "    \n",
    "    layer2_error = layer3_delta.dot(w2.T)\n",
    "    layer2_delta = layer2_error * relu_deriv(layer2)\n",
    "    \n",
    "    layer1_error = layer2_delta.dot(w1.T)\n",
    "    layer1_delta = layer1_error * relu_deriv(layer1)\n",
    "    \n",
    "    w2 += layer2.T.dot(layer3_delta) * lr\n",
    "    w1 += layer1.T.dot(layer2_delta) * lr\n",
    "    w0 += layer0.T.dot(layer1_delta) * lr\n",
    "    \n",
    "    error = np.mean(np.abs(layer3_error))\n",
    "    errors.append(error)\n",
    "    accuracy = (1 - error) * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "d221d737",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.94"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trlayer0 = X_train\n",
    "trlayer1 = relu(np.dot(trlayer0, w0))\n",
    "trlayer2 = relu(np.dot(trlayer1, w1))\n",
    "trlayer3 = sigmoid(np.dot(trlayer2, w2))\n",
    "accuracy_score(y_train.argmax(axis=1), trlayer3.argmax(axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "3d6ba41b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tlayer0 = X_test\n",
    "tlayer1 = relu(np.dot(tlayer0, w0))\n",
    "tlayer2 = relu(np.dot(tlayer1, w1))\n",
    "tlayer3 = sigmoid(np.dot(tlayer2, w2))\n",
    "accuracy_score(y_test.argmax(axis=1), tlayer3.argmax(axis=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eff2d6e9",
   "metadata": {},
   "source": [
    "### PyTorch implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "b594c42c",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x = torch.as_tensor(X_train, dtype=torch.float32)\n",
    "test_x = torch.as_tensor(X_test, dtype=torch.float32)\n",
    "train_y = torch.as_tensor(y_train.argmax(axis=1))\n",
    "test_y = torch.as_tensor(y_test.argmax(axis=1))\n",
    "\n",
    "train_ds = TensorDataset(train_x, train_y)\n",
    "test_ds = TensorDataset(test_x, test_y)\n",
    "\n",
    "batch_size = 8\n",
    "train_dl = DataLoader(train_ds, batch_size=batch_size, shuffle=True)\n",
    "test_dl = DataLoader(test_ds, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "1f5d4663",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cuda'"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "193c54a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = nn.Sequential(\n",
    "            nn.Linear(4, 20),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(20, 10),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(10, 3)\n",
    ").to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "ba8a57ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)  # продвинутый SGD, динамически подстраивает Lr каждого параметра\n",
    "epochs = 10000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "8925229e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████| 10000/10000 [04:32<00:00, 36.65it/s]\n"
     ]
    }
   ],
   "source": [
    "train_acc, test_acc = 0, 0\n",
    "\n",
    "for epoch in trange(epochs):\n",
    "    model.train()\n",
    "    running_train, running_test = 0, 0 \n",
    "    for batch in train_dl:\n",
    "        optimizer.zero_grad()\n",
    "        x, y = batch\n",
    "        x, y = x.to(device), y.to(device)\n",
    "        out = model(x.to(device))\n",
    "        loss = criterion(out, y.to(device))\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        out = torch.max(out, 1)[1]\n",
    "        running_train += (out == y).float().mean()\n",
    "    train_acc += (running_train.item() / len(train_dl))\n",
    "    \n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for batch in test_dl:\n",
    "            x, y = batch\n",
    "            x, y = x.to(device), y.to(device)\n",
    "            out = model(x.to(device))\n",
    "            loss = criterion(out, y.to(device))\n",
    "            out = torch.max(out, 1)[1]\n",
    "            running_test += (out == y).float().mean()\n",
    "        test_acc += (running_test.item() / len(test_dl))\n",
    "        \n",
    "train_acc /= epochs\n",
    "test_acc /= epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "62748a4f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.9596403846154723, 0.9972071428571436)"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_acc, test_acc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f6b3b24",
   "metadata": {},
   "source": [
    "**Выводы**\n",
    "* Важно граммотно инициализировать веса (0 - это провал, нормальное распределение (или другое в зависимости от задачи - норм));\n",
    "* Важно выбрать скорость обучения: при высоком мы будем проскакивать минимум функции, при маленьком модель будет слишком долго сходиться;\n",
    "* Выбрать количество эпох: модель может либо недообучиться или переобучиться (можно выбрать много, но с динамической скоростью обучения и, возможно, с ранней остановкой);\n",
    "* Важно определить архитектуру сети: слишком много слоев для простой задачи - плохой выбор, слишком мало для сложной - ничему не научится. Кроме того важно выбрать сами слои и функции активации, сигмоида для скрытых слоев - это провал (затухающие градиенты, например);\n",
    "* Важно корректно подобрать размер скрытых слоев - зависит от сложности и типа задачи (слишком мало нейронов приведет к тому, что сеть не уловит важных закономерностей, слишком большое - к снижению точности)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:test1] *",
   "language": "python",
   "name": "conda-env-test1-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
